{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd5357e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ferrovia</th>\n",
       "      <th>Mercadoria_ANTT</th>\n",
       "      <th>Estacao_Origem</th>\n",
       "      <th>UF_Origem</th>\n",
       "      <th>Estacao_Destino</th>\n",
       "      <th>UF_Destino</th>\n",
       "      <th>TU</th>\n",
       "      <th>M√äS</th>\n",
       "      <th>ANO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EFC</td>\n",
       "      <td>√Ålcool</td>\n",
       "      <td>Itaqui Base Combust√≠vel</td>\n",
       "      <td>MA</td>\n",
       "      <td>Marab√°</td>\n",
       "      <td>PA</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EFC</td>\n",
       "      <td>Bebidas e Vasilhames</td>\n",
       "      <td>Ponta da Madeira P√™ra do P√≠er</td>\n",
       "      <td>MA</td>\n",
       "      <td>Imperatriz</td>\n",
       "      <td>MA</td>\n",
       "      <td>1636</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EFC</td>\n",
       "      <td>Cobre</td>\n",
       "      <td>Paraupebas</td>\n",
       "      <td>PA</td>\n",
       "      <td>Ponta da Madeira Cobre</td>\n",
       "      <td>MA</td>\n",
       "      <td>24461</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EFC</td>\n",
       "      <td>Ferro Gusa</td>\n",
       "      <td>A√ßail√¢ndia</td>\n",
       "      <td>MA</td>\n",
       "      <td>Ponta da Madeira P√™ra do P√≠er</td>\n",
       "      <td>MA</td>\n",
       "      <td>116272</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EFC</td>\n",
       "      <td>Ferro Gusa</td>\n",
       "      <td>Marab√°</td>\n",
       "      <td>PA</td>\n",
       "      <td>Ponta da Madeira P√™ra do P√≠er</td>\n",
       "      <td>MA</td>\n",
       "      <td>205242</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148653</th>\n",
       "      <td>RMS</td>\n",
       "      <td>Soja</td>\n",
       "      <td>Marialva</td>\n",
       "      <td>PR</td>\n",
       "      <td>D Pedro II</td>\n",
       "      <td>PR</td>\n",
       "      <td>179173</td>\n",
       "      <td>4</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148654</th>\n",
       "      <td>RMS</td>\n",
       "      <td>Soja</td>\n",
       "      <td>Marialva</td>\n",
       "      <td>PR</td>\n",
       "      <td>S√£o Francisco do Sul</td>\n",
       "      <td>SC</td>\n",
       "      <td>80527</td>\n",
       "      <td>4</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148655</th>\n",
       "      <td>RMS</td>\n",
       "      <td>Soja</td>\n",
       "      <td>Maringa</td>\n",
       "      <td>PR</td>\n",
       "      <td>D Pedro II</td>\n",
       "      <td>PR</td>\n",
       "      <td>193917</td>\n",
       "      <td>4</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148656</th>\n",
       "      <td>RMS</td>\n",
       "      <td>Soja</td>\n",
       "      <td>Maringa</td>\n",
       "      <td>PR</td>\n",
       "      <td>Rio Grande</td>\n",
       "      <td>RS</td>\n",
       "      <td>1710</td>\n",
       "      <td>4</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148657</th>\n",
       "      <td>RMS</td>\n",
       "      <td>Soja</td>\n",
       "      <td>Maringa</td>\n",
       "      <td>PR</td>\n",
       "      <td>S√£o Francisco do Sul</td>\n",
       "      <td>SC</td>\n",
       "      <td>189848</td>\n",
       "      <td>4</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148617 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Ferrovia       Mercadoria_ANTT                 Estacao_Origem  \\\n",
       "0           EFC                √Ålcool        Itaqui Base Combust√≠vel   \n",
       "1           EFC  Bebidas e Vasilhames  Ponta da Madeira P√™ra do P√≠er   \n",
       "2           EFC                 Cobre                     Paraupebas   \n",
       "3           EFC            Ferro Gusa                     A√ßail√¢ndia   \n",
       "4           EFC            Ferro Gusa                         Marab√°   \n",
       "...         ...                   ...                            ...   \n",
       "148653      RMS                  Soja                       Marialva   \n",
       "148654      RMS                  Soja                       Marialva   \n",
       "148655      RMS                  Soja                        Maringa   \n",
       "148656      RMS                  Soja                        Maringa   \n",
       "148657      RMS                  Soja                        Maringa   \n",
       "\n",
       "       UF_Origem                Estacao_Destino UF_Destino      TU  M√äS   ANO  \n",
       "0             MA                         Marab√°         PA     184    1  2006  \n",
       "1             MA                     Imperatriz         MA    1636    1  2006  \n",
       "2             PA         Ponta da Madeira Cobre         MA   24461    1  2006  \n",
       "3             MA  Ponta da Madeira P√™ra do P√≠er         MA  116272    1  2006  \n",
       "4             PA  Ponta da Madeira P√™ra do P√≠er         MA  205242    1  2006  \n",
       "...          ...                            ...        ...     ...  ...   ...  \n",
       "148653        PR                     D Pedro II         PR  179173    4  2023  \n",
       "148654        PR           S√£o Francisco do Sul         SC   80527    4  2023  \n",
       "148655        PR                     D Pedro II         PR  193917    4  2023  \n",
       "148656        PR                     Rio Grande         RS    1710    4  2023  \n",
       "148657        PR           S√£o Francisco do Sul         SC  189848    4  2023  \n",
       "\n",
       "[148617 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "\n",
    "GUILHERME LIMA DE SOUSA - \n",
    "ESTUDO DE CASO: TONELADAS TRANSPORTADAS EM FERROVIAS BRASILEIRAS\n",
    "OBJETIVO: PREDI√á√ÉO USANDO RANDOMFORESTREGRESSOR\n",
    "\n",
    "ENTRE EM CONTATO COMIGO NO LINKEDIN: \n",
    "www.linkedin.com/in/guilherme-lima-747355169\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import random\n",
    "import mlflow\n",
    "\n",
    "\n",
    "################################################################################\n",
    "\n",
    "\n",
    "# ETL DA BASE\n",
    "\n",
    "################################################################################\n",
    "\n",
    "\n",
    "\n",
    "##CONFIGURANDO NUMEROS COM 2 CASAS DECIMAIS\n",
    "pd.set_option('Float_format','{:.2f}'.format)\n",
    "\n",
    "## COMPILANDO ARQUIVOS DA PASTA\n",
    "pasta = 'C:/Users/Guilh/OneDrive/√Årea de Trabalho/1-MATERIAIS DE ESTUDO/01 - DIVERSOS/01-SCIKIT_LEARN/02-RANDOMFOREST/1-ANTT_FERROVIAS/01-INPUT'\n",
    "arquivos = glob.glob(os.path.join(pasta, '*.csv'))\n",
    "base_original = pd.concat([pd.read_csv(i, sep=';', encoding='latin1') for i in arquivos], ignore_index = True)\n",
    "\n",
    "## REMOVENDO PONTO DA COLUNA\n",
    "base_original['TU'] = base_original['TU'].str.replace('.','',regex=False)\n",
    "base_original['TKU'] = base_original['TKU'].str.replace('.','',regex=False)\n",
    "\n",
    "## ALTERANDO FORMATA√á√ÉO DA COLUNA\n",
    "base_original['TKU'] = base_original['TKU'].fillna(0)\n",
    "base_original['TKU'] = base_original['TKU'].astype(float)\n",
    "base_original['TU'] = base_original['TU'].astype(int)\n",
    "base_original['TKU'] = base_original['TKU'].astype(int)\n",
    "base_original['Mes_Ano'] = pd.to_datetime(base_original['Mes_Ano'], format='%m/%Y')\n",
    "\n",
    "## CRIANDO COLUNAS\n",
    "base_original['M√äS'] = base_original['Mes_Ano'].dt.month\n",
    "base_original['ANO'] = base_original['Mes_Ano'].dt.year\n",
    "\n",
    "#REMOVENDO DUPLICADOS E NULOS\n",
    "base_original = base_original.drop_duplicates()\n",
    "\n",
    "# REMOVENDO COLUNA TKU POIS O OBJETIVO √â APNAS TU\n",
    "base_original = base_original.drop('TKU', axis=1)\n",
    "base_original = base_original.drop('Mes_Ano', axis=1)\n",
    "\n",
    "# REMOVENDO VALORES ABAIXO DE 1 TONELADA\n",
    "base_original = base_original[base_original[\"TU\"]>= 1]\n",
    "\n",
    "# VENDO A BASE\n",
    "base_original.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "573b33e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "################# BASE COM DE:PARA ########################\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ferrovia</th>\n",
       "      <th>Mercadoria_ANTT</th>\n",
       "      <th>Estacao_Origem</th>\n",
       "      <th>UF_Origem</th>\n",
       "      <th>Estacao_Destino</th>\n",
       "      <th>UF_Destino</th>\n",
       "      <th>TU</th>\n",
       "      <th>M√äS</th>\n",
       "      <th>ANO</th>\n",
       "      <th>Codigo_Ferrovia</th>\n",
       "      <th>Codigo_Mercadoria_ANTT</th>\n",
       "      <th>Codigo_Estacao_Origem</th>\n",
       "      <th>Codigo_UF_Origem</th>\n",
       "      <th>Codigo_Estacao_Destino</th>\n",
       "      <th>Codigo_UF_Destino</th>\n",
       "      <th>cluster_produto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EFC</td>\n",
       "      <td>√Ålcool</td>\n",
       "      <td>Itaqui Base Combust√≠vel</td>\n",
       "      <td>MA</td>\n",
       "      <td>Marab√°</td>\n",
       "      <td>PA</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>216</td>\n",
       "      <td>5</td>\n",
       "      <td>234</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EFC</td>\n",
       "      <td>Bebidas e Vasilhames</td>\n",
       "      <td>Ponta da Madeira P√™ra do P√≠er</td>\n",
       "      <td>MA</td>\n",
       "      <td>Imperatriz</td>\n",
       "      <td>MA</td>\n",
       "      <td>1636</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>316</td>\n",
       "      <td>5</td>\n",
       "      <td>187</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EFC</td>\n",
       "      <td>Cobre</td>\n",
       "      <td>Paraupebas</td>\n",
       "      <td>PA</td>\n",
       "      <td>Ponta da Madeira Cobre</td>\n",
       "      <td>MA</td>\n",
       "      <td>24461</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>293</td>\n",
       "      <td>9</td>\n",
       "      <td>296</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EFC</td>\n",
       "      <td>Cobre</td>\n",
       "      <td>Paraupebas</td>\n",
       "      <td>PA</td>\n",
       "      <td>Ponta da Madeira Cobre</td>\n",
       "      <td>MA</td>\n",
       "      <td>24461</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>293</td>\n",
       "      <td>9</td>\n",
       "      <td>296</td>\n",
       "      <td>5</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EFC</td>\n",
       "      <td>Ferro Gusa</td>\n",
       "      <td>A√ßail√¢ndia</td>\n",
       "      <td>MA</td>\n",
       "      <td>Ponta da Madeira P√™ra do P√≠er</td>\n",
       "      <td>MA</td>\n",
       "      <td>116272</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>297</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ferrovia       Mercadoria_ANTT                 Estacao_Origem UF_Origem  \\\n",
       "0      EFC                √Ålcool        Itaqui Base Combust√≠vel        MA   \n",
       "1      EFC  Bebidas e Vasilhames  Ponta da Madeira P√™ra do P√≠er        MA   \n",
       "2      EFC                 Cobre                     Paraupebas        PA   \n",
       "3      EFC                 Cobre                     Paraupebas        PA   \n",
       "4      EFC            Ferro Gusa                     A√ßail√¢ndia        MA   \n",
       "\n",
       "                 Estacao_Destino UF_Destino      TU  M√äS   ANO  \\\n",
       "0                         Marab√°         PA     184    1  2006   \n",
       "1                     Imperatriz         MA    1636    1  2006   \n",
       "2         Ponta da Madeira Cobre         MA   24461    1  2006   \n",
       "3         Ponta da Madeira Cobre         MA   24461    1  2006   \n",
       "4  Ponta da Madeira P√™ra do P√≠er         MA  116272    1  2006   \n",
       "\n",
       "   Codigo_Ferrovia  Codigo_Mercadoria_ANTT  Codigo_Estacao_Origem  \\\n",
       "0                0                      98                    216   \n",
       "1                0                      11                    316   \n",
       "2                0                      22                    293   \n",
       "3                0                      22                    293   \n",
       "4                0                      44                     36   \n",
       "\n",
       "   Codigo_UF_Origem  Codigo_Estacao_Destino  Codigo_UF_Destino  \\\n",
       "0                 5                     234                  9   \n",
       "1                 5                     187                  5   \n",
       "2                 9                     296                  5   \n",
       "3                 9                     296                  5   \n",
       "4                 5                     297                  5   \n",
       "\n",
       "   cluster_produto  \n",
       "0              NaN  \n",
       "1             1.00  \n",
       "2             0.00  \n",
       "3             2.00  \n",
       "4             0.00  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "#     CRIANDO DATASET DO MODELO\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "'''\n",
    "\n",
    "AQUI VAMOS CRIAR O DATASET DO MODELO\n",
    "FAZENDO ETL COM AS COLUNAS CATEGORICAS E APLICANDO C√ìDIGOS PARA CADA UMA, \n",
    "POSTERIORMENTE USANDO AS COLUNAS NUMERICAS REPRESENTADAS COMO VARIAVEIS DO MODELO.\n",
    "EM VEZ DE USAR O NOME DA FERROVIA ESTAMOS CRIANDO UM C√ìDIGO DISTINTO DELA.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# REPRODUTIBILIDADE\n",
    "np.random.seed(2)\n",
    "\n",
    "\n",
    "## BASE MODELO\n",
    "#print(base_original.columns)\n",
    "print('--------------------')\n",
    "base_modelo = base_original\n",
    "\n",
    "# TRANSFORMANDO COLUNAS\n",
    "base_modelo['ANO'] = base_modelo['ANO'].astype(int)\n",
    "base_modelo['M√äS'] = base_modelo['M√äS'].astype(int)\n",
    "base_modelo['TU'] = base_modelo['TU'].astype(int)\n",
    "\n",
    "#\n",
    "############### CRIANDO OS C√ìDIGOS DE CADA CATEGORIA\n",
    "# SELECIONA APENAS AS COLUNAS STRING/CATEGORIAS/OBJETO\n",
    "categ = base_modelo.select_dtypes(include=['object', 'category']).copy()\n",
    "# LAMBDA QUE TRANSFORMA AS COLUNAS E NUMEROS\n",
    "cod_categorica_hoje_1 = categ.apply(lambda col: col.astype('category').cat.codes)\n",
    "# RENOMEANDO AS COLUNAS DE CODIGO COM PREFIXO\n",
    "cod_categorica_1 = cod_categorica_hoje_1.add_prefix('Codigo_')\n",
    "\n",
    "\n",
    "# CONCATENANDO AS BASES DE CODIGOS COM A ORIGINAL\n",
    "codigos_categorias = pd.concat([base_modelo, cod_categorica_1], axis=1)\n",
    "\n",
    "print('################# BASE COM DE:PARA ########################\\n')\n",
    "# BASE COM TUDO\n",
    "\n",
    "\n",
    "\n",
    "##########  PARA VISUALIZAR DE:PARA DE COLUNA ESPECIFICA\n",
    "#visualizar_de_para = codigos_categorias[['Ferrovia', 'Codigo_Ferrovia']].drop_duplicates().reset_index(drop=True)\n",
    "#print('\\n################# VERIFICAR ########################\\n')\n",
    "#print(visualizar_de_para.head(3))\n",
    "\n",
    "\n",
    "########## ENGENHARIA DE ATRIBUTOS - FEATURE ENGINEERING - CLUSTER KMEANS\n",
    "grupos_produtos = pd.read_csv('BASE_ANTT_COM_KMEANS.csv', sep=';')\n",
    "grupos_produtos = grupos_produtos.iloc[:,[2,3,4,5,6,7,9]].drop_duplicates()\n",
    "\n",
    "\n",
    "mesclando_df = codigos_categorias.merge(grupos_produtos,how=\"left\", on=['Codigo_Ferrovia',\n",
    "                                                                     'Codigo_Mercadoria_ANTT',\n",
    "                                                                     'Codigo_Estacao_Origem',\n",
    "                                                                     'Codigo_UF_Origem',\n",
    "                                                                     'Codigo_Estacao_Destino',\n",
    "                                                                     'Codigo_UF_Destino'])\n",
    "\n",
    "codigos_categorias = mesclando_df\n",
    "codigos_categorias.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca6dcea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################# BASE MODELO ########################\n",
      "   M√äS   ANO  Codigo_Ferrovia  Codigo_Mercadoria_ANTT  Codigo_Estacao_Origem  \\\n",
      "1    1  2006                0                      11                    316   \n",
      "2    1  2006                0                      22                    293   \n",
      "3    1  2006                0                      22                    293   \n",
      "\n",
      "   Codigo_UF_Origem  Codigo_Estacao_Destino  Codigo_UF_Destino  \\\n",
      "1                 5                     187                  5   \n",
      "2                 9                     296                  5   \n",
      "3                 9                     296                  5   \n",
      "\n",
      "   cluster_produto  TU_LOG10  \n",
      "1             1.00      3.21  \n",
      "2             0.00      4.39  \n",
      "3             2.00      4.39  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M√äS</th>\n",
       "      <th>ANO</th>\n",
       "      <th>Codigo_Ferrovia</th>\n",
       "      <th>Codigo_Mercadoria_ANTT</th>\n",
       "      <th>Codigo_Estacao_Origem</th>\n",
       "      <th>Codigo_UF_Origem</th>\n",
       "      <th>Codigo_Estacao_Destino</th>\n",
       "      <th>Codigo_UF_Destino</th>\n",
       "      <th>cluster_produto</th>\n",
       "      <th>TU_LOG10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>124771.00</td>\n",
       "      <td>124771.00</td>\n",
       "      <td>124771.00</td>\n",
       "      <td>124771.00</td>\n",
       "      <td>124771.00</td>\n",
       "      <td>124771.00</td>\n",
       "      <td>124771.00</td>\n",
       "      <td>124771.00</td>\n",
       "      <td>124771.00</td>\n",
       "      <td>124771.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.55</td>\n",
       "      <td>2013.40</td>\n",
       "      <td>6.89</td>\n",
       "      <td>52.05</td>\n",
       "      <td>231.22</td>\n",
       "      <td>10.18</td>\n",
       "      <td>219.09</td>\n",
       "      <td>11.61</td>\n",
       "      <td>0.54</td>\n",
       "      <td>4.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.44</td>\n",
       "      <td>4.97</td>\n",
       "      <td>3.95</td>\n",
       "      <td>30.80</td>\n",
       "      <td>127.77</td>\n",
       "      <td>5.38</td>\n",
       "      <td>121.51</td>\n",
       "      <td>5.64</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>2006.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.00</td>\n",
       "      <td>2009.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>128.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>120.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.00</td>\n",
       "      <td>2013.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>52.00</td>\n",
       "      <td>242.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>228.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.00</td>\n",
       "      <td>2018.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>341.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>331.00</td>\n",
       "      <td>18.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.00</td>\n",
       "      <td>2022.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>101.00</td>\n",
       "      <td>437.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>410.00</td>\n",
       "      <td>19.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>7.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            M√äS       ANO  Codigo_Ferrovia  Codigo_Mercadoria_ANTT  \\\n",
       "count 124771.00 124771.00        124771.00               124771.00   \n",
       "mean       6.55   2013.40             6.89                   52.05   \n",
       "std        3.44      4.97             3.95                   30.80   \n",
       "min        1.00   2006.00             0.00                    0.00   \n",
       "25%        4.00   2009.00             3.00                   23.00   \n",
       "50%        7.00   2013.00             7.00                   52.00   \n",
       "75%       10.00   2018.00            12.00                   81.00   \n",
       "max       12.00   2022.00            12.00                  101.00   \n",
       "\n",
       "       Codigo_Estacao_Origem  Codigo_UF_Origem  Codigo_Estacao_Destino  \\\n",
       "count              124771.00         124771.00               124771.00   \n",
       "mean                  231.22             10.18                  219.09   \n",
       "std                   127.77              5.38                  121.51   \n",
       "min                     1.00              0.00                    0.00   \n",
       "25%                   128.00              6.00                  120.00   \n",
       "50%                   242.00              9.00                  228.00   \n",
       "75%                   341.00             15.00                  331.00   \n",
       "max                   437.00             19.00                  410.00   \n",
       "\n",
       "       Codigo_UF_Destino  cluster_produto  TU_LOG10  \n",
       "count          124771.00        124771.00 124771.00  \n",
       "mean               11.61             0.54      4.02  \n",
       "std                 5.64             0.99      0.67  \n",
       "min                 0.00             0.00      3.00  \n",
       "25%                 6.00             0.00      3.51  \n",
       "50%                13.00             0.00      3.92  \n",
       "75%                18.00             1.00      4.41  \n",
       "max                19.00             3.00      7.14  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################################################################\n",
    "\n",
    "#     TRANSFORMANDO DATASET DO MODELO RANDOMFOREST\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "''' \n",
    "AQUI ESTOU REMOVENDO OS VALORES MENORES DE 1000 MIL TONELADAS DE MOVIMENTA√á√ÉO\n",
    "POIS ABAIXO DE MIL DEIXA O MODELO RUIM, MUITO COMPLEXO PRA ENTENDER OS DADOS\n",
    "QUE VARIAM DE ZERO A MILHOES.\n",
    "\n",
    "'''\n",
    "# CRIANDO A BASE\n",
    "base_treino = codigos_categorias.select_dtypes(exclude=['object', 'category']).copy()\n",
    "\n",
    "#REMOVENDO DUPLICADOS\n",
    "base_treino = base_treino.drop_duplicates()\n",
    "base_treino = base_treino.fillna(0)\n",
    "\n",
    "# SALVANDO BASE DO MODELO COMPLETA SEM FILTROS\n",
    "base_modelo_completa = base_treino\n",
    "\n",
    "# LIMITANDO A BASE REMOVENDO 2023\n",
    "base_treino = base_treino[base_treino['ANO'] != 2023][list(base_treino.columns)]\n",
    "\n",
    "\n",
    "# REMOVENDO OS OUTLIERS - TUDO QUE √â MENOR DE MIL TONELADAS\n",
    "base_treino = base_treino[base_treino['TU'] >= 1000.00]\n",
    "base_modelo = base_treino\n",
    "\n",
    "\n",
    "# REMOVENDO OS OUTLIERS - TUDO QUE EST√Å MAIOR DO 3¬∫ QUARTIL EM TONELADAS\n",
    "#q3 = base_treino['TU'].quantile(0.75)\n",
    "#base_treino = base_treino[base_treino['TU'] <= q3]\n",
    "#base_modelo = base_treino\n",
    "\n",
    "\n",
    "\n",
    "# LOGARITMO BASE10\n",
    "base_modelo['TU_LOG10'] = np.log10(base_modelo['TU'])\n",
    "\n",
    "\n",
    "# REMOVENDO COLUNA REAL\n",
    "base_modelo = base_modelo.drop('TU', axis=1)\n",
    "\n",
    "\n",
    "base_modelo = base_modelo[[\"M√äS\", \"ANO\", \"Codigo_Ferrovia\", \"Codigo_Mercadoria_ANTT\",\n",
    "                          \"Codigo_Estacao_Origem\", \"Codigo_UF_Origem\", \"Codigo_Estacao_Destino\",\n",
    "                          \"Codigo_UF_Destino\", \"cluster_produto\", \"TU_LOG10\"]]\n",
    "\n",
    "\n",
    "print('################# BASE MODELO ########################')\n",
    "print(base_modelo.head(3))\n",
    "base_modelo.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "648f07ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/01 18:29:45 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\Guilh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/02/01 18:30:13 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\Guilh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n",
      "2026/02/01 18:31:24 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\Guilh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run peaceful-crab-471 at: http://127.0.0.1:5000/#/experiments/540394382883761644/runs/7caa658643b24316be6b11298dcb943f\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/540394382883761644\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "\n",
    "HIP√ìTESE NULA = SER√Å QUE MEU MODELO CONSEGUE EXPLICAR AS TONELADAS TRANSPORTADAS\n",
    "APENAS COM AS DEMAIS COLUNAS DO NOSSO DATASET ?\n",
    "\n",
    "\n",
    "############# PARAMETROS DO MODELO\n",
    "MODELO COM VALIDA√á√ÉO CRUZADA DE 5 FOLDS CRIADO COM OS PARAMETROS:\n",
    "\n",
    "N_ESTIMATORS = 300\n",
    "300 ARVORES DE DECIS√ÉO NO M√ÅXIMO\n",
    "\n",
    "MAXDEPTH = 15\n",
    "PERMITE CRIAR ARVORES MAIS PROFUNDAS E TRAZ ALEATORIEDADE AOS DADOS, GENERALIZA√á√ÉO.\n",
    "\n",
    "RANDOM_STATE = 2\n",
    "REPLICABILIDADE DE RESULTADOS\n",
    "\n",
    "MAX_FEATURES = 'SQRT' \n",
    "ELE N√ÉO USA TODAS AS FEATURES NOS N√ìS, ELE USA A RAIZ QUADRADA DO TOTAL DE COLUNAS.\n",
    "DESTA FORMA O MODELO √â FOR√áADO COM DADOS E CEN√ÅRIOS COMPLEXOS.\n",
    "\n",
    "MIN_SAMPLES_SPLIT = 10\n",
    "O MODELO S√ì VAI CRIAR OUTRO N√ì SE TIVER PELO MENOS 10 REGISTROS PRA SEGUIR ADIANTE\n",
    "\n",
    "MIN_SAMPLES_LEAF = 5\n",
    "CADA FOLHA FINAL DEVE CONTER PELO MENOS 5 REGISTROS\n",
    "\n",
    "\n",
    "############# AVALIA√á√ïES\n",
    "# MAE (ERRO ABSOLUTO MEDIO)\n",
    "Em m√©dia, o modelo erra cerca de 38.327 toneladas na previs√£o de TU. Esse valor deve ser \n",
    "interpretado em rela√ß√£o √† escala dos dados ‚Äî se TU varia de 0 a milh√µes, esse erro pode ser toler√°vel; se n√£o, \n",
    "pode ser alto ......Em nossa base a coluna TARGET varia entre 0 e 13.858.719 ent√£o 38.327 √© toler√°vel\n",
    "\n",
    "# MSE (MEAN SQUARED ERROR) - M√©dia dos erros ao quadrado. \n",
    "Penaliza fortemente grandes erros e destaca discrep√¢ncias mais severas.\n",
    "\n",
    "# MAPE\n",
    "Este √© o erro m√©dio (MAE) s√≥ que em percentual.\n",
    "\n",
    "# RMSE\n",
    "Raiz do erro quadratico m√©dio - (Raise mean squared error)\n",
    "Esse erro penaliza mais fortemente grandes erros. Um RMSE muito maior que o MAE (como no nosso cenario 274.067) indica que \n",
    "h√° outliers ou erros muito grandes em alguns casos que est√£o influenciando bastante a performance.\n",
    "\n",
    "# MEDAE\n",
    "Este √© a mediana dos erros, mostra como os erros est√£o distribuidos, o meio entre eles.\n",
    "\n",
    "Avaliamos:\n",
    "MAE para entender o erro m√©dio bruto.\n",
    "MAPE √© o MAE em %.\n",
    "RMSE se quiser punir grandes erros, fica sempre maior mas n√£o tanto.\n",
    "MedAE onde √© o meio ? mediana dos erros.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "############################################################################\n",
    "\n",
    "\n",
    "#  MODELO PRINCIPAL\n",
    "\n",
    "############################################################################\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split, learning_curve, TimeSeriesSplit\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, median_absolute_error\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "\n",
    "## DEFININDO MLFLOW\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")\n",
    "mlflow.set_experiment(experiment_id=540394382883761644)\n",
    "\n",
    "\n",
    "# REPRODUTIBILIDADE\n",
    "np.random.seed(2)\n",
    "\n",
    "base_modelo = base_modelo.sort_values(by=[\"ANO\", \"M√äS\"])\n",
    "########################  CRIANDO MODELO PRINCIPAL\n",
    "# DEFININDO X (VAR DEPENDENTE) Y (VAR TARGET)\n",
    "x = base_modelo.drop(columns=['TU_LOG10'])\n",
    "y = base_modelo['TU_LOG10']\n",
    "\n",
    "\n",
    "# ORDENA√á√ÉO DOS DADOS PARA A BASE DE TREINO\n",
    "x = x[['M√äS', 'ANO', 'Codigo_Ferrovia', 'Codigo_Mercadoria_ANTT', 'Codigo_Estacao_Origem',\n",
    "                                           'Codigo_UF_Origem', 'Codigo_Estacao_Destino', 'Codigo_UF_Destino',\"cluster_produto\"]]\n",
    "\n",
    "\n",
    "# SEPARANDO TREINO E TESTE\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.1)\n",
    "\n",
    "\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.sklearn.autolog()\n",
    "    # CRIANDO MODELO\n",
    "    modelo = RandomForestRegressor(n_estimators=300, \n",
    "                                max_depth=20, \n",
    "                                random_state=2, \n",
    "                                max_features='sqrt', \n",
    "                                min_samples_split=10, \n",
    "                                min_samples_leaf=5)\n",
    "\n",
    "    # VALIDA√á√ÉO CRUZADA\n",
    "    kf = KFold(n_splits=5, shuffle= True, random_state=2)\n",
    "    cross_validation = cross_val_score(modelo, x, y, cv=kf, scoring='r2')\n",
    "\n",
    "    # APLICANDO LOG() PARA MELHORAR A DISTRIBUI√á√ÉO DO MODELO - evita heterocedasticidade\n",
    "    #y_train_log = np.log1p(y_train)\n",
    "\n",
    "\n",
    "    # TREINANDO O MODELO\n",
    "    modelo.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "    # USANDO MODELO NO COJUNTO DE TESTE - PREDI√á√ÉO\n",
    "    y_pred = modelo.predict(x_test)\n",
    "\n",
    "\n",
    "    # OBTENDO R2 DA PREDI√á√ÉO ANTERIOR\n",
    "    ACC_MODELO = r2_score(y_test, y_pred)\n",
    "\n",
    "    # ERRO PERCENTUAL M√âDIO COM LOG10\n",
    "    MAE_LOG10 = mean_absolute_error(y_test, y_pred)\n",
    "    MSE_LOG10 = mean_squared_error(y_test, y_pred)\n",
    "    RMSE_LOG10 = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    MAPE_LOG10 = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    MEDAE_LOG10 = median_absolute_error(y_test, y_pred)\n",
    "\n",
    "\n",
    "    # ERRO PERCENTUAL M√âDIO SEM LOG10\n",
    "    MAE_REAL = mean_absolute_error(10**y_test, 10**y_pred)\n",
    "    MSE_REAL = mean_squared_error(10**y_test, 10**y_pred)\n",
    "    RMSE_REAL = np.sqrt(mean_squared_error(10**y_test, 10**y_pred))\n",
    "    MAPE_REAL = mean_absolute_percentage_error(10**y_test, 10**y_pred)\n",
    "    MEDAE_REAL = median_absolute_error(10**y_test, 10**y_pred)\n",
    "\n",
    "\n",
    "    ##########  DEFININDO AS METRICAS QUE VAO PARA O MLFLOW\n",
    "    metricas_mlflow = {\n",
    "    \"MAE_LOG10\": MAE_LOG10,\n",
    "    \"MSE_LOG10\": MSE_LOG10,\n",
    "    \"RMSE_LOG10\": RMSE_LOG10,\n",
    "    \"MAPE_LOG10\": MAPE_LOG10,\n",
    "    \"MEDAE_LOG10\": MEDAE_LOG10,\n",
    "\n",
    "    \"MAE_REAL\": MAE_REAL,\n",
    "    \"MSE_REAL\": MSE_REAL,\n",
    "    \"RMSE_REAL\": RMSE_REAL,\n",
    "    \"MAPE_REAL\": MAPE_REAL,\n",
    "    \"MEDAE_REAL\": MEDAE_REAL,\n",
    "    \"ACC_MODELO\": ACC_MODELO}\n",
    "\n",
    "    mlflow.log_metrics(metricas_mlflow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
